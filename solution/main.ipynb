{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0cbec8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1155e7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ------------------------------------------------No.1------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "no1 = \"No.1\"\n",
    "no1 = no1.center(100,\"-\")\n",
    "print(f\"\\n\",no1)\n",
    "\n",
    "# create a function to load all the JSON files inside a folder and normalize them then append the files into a data_list\n",
    "def load_and_normalize(folder_path):\n",
    "    data_list = []\n",
    "\n",
    "    # loop into the folder, scanning all the files inside the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        with open(file_path,'r') as f:\n",
    "            data = json.load(f)\n",
    "            data_list.append(data)\n",
    "            \n",
    "    # normalize the datas inside data_list and update the data_list directly\n",
    "    data_list = pd.json_normalize(data_list)\n",
    "    \n",
    "    # sort the datas inside data_list ny id and ts(timestamp)\n",
    "    data_list = data_list.sort_values(by=['id','ts'])\n",
    "    \n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "18c1c39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.environ.get(\"DATA_FOLDER\", \"./data\")\n",
    "accounts_path = os.path.join(data_folder,'accounts')\n",
    "cards_path = os.path.join(data_folder,'cards')\n",
    "savings_accounts_path = os.path.join(data_folder,'savings_accounts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ae911e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ACCOUNTS:\n",
      "  account_id     name   address phone_number                    email savings_account_id card_id\n",
      "0         a1  Anthony  New York     12345678     anthony@somebank.com                NaN     NaN\n",
      "1         a1  Anthony  New York     87654321     anthony@somebank.com                NaN     NaN\n",
      "2         a1  Anthony  New York     87654321     anthony@somebank.com                sa1     NaN\n",
      "3         a1  Anthony   Jakarta     87654321  anthony@anotherbank.com                sa1     NaN\n",
      "4         a1  Anthony   Jakarta     87654321  anthony@anotherbank.com                sa1      c1\n",
      "5         a1  Anthony   Jakarta     87654321  anthony@anotherbank.com                sa1        \n",
      "6         a1  Anthony   Jakarta     87654321  anthony@anotherbank.com                sa1      c2\n"
     ]
    }
   ],
   "source": [
    "# Feeling dataframe \"df_accounts\" with all the JSON data files located in \"./data/accounts\" using load_and_normalize function\n",
    "df_accounts = load_and_normalize(\"./data/accounts\")\n",
    "\n",
    "# renaming and combining the features/columns\n",
    "df_accounts[\"account_id\"] = df_accounts[\"data.account_id\"]\n",
    "df_accounts[\"name\"] = df_accounts[\"data.name\"]\n",
    "df_accounts[\"email\"] = df_accounts[\"set.email\"].combine_first(df_accounts[\"data.email\"])\n",
    "df_accounts[\"savings_account_id\"] = df_accounts[\"set.savings_account_id\"]\n",
    "df_accounts[\"card_id\"] = df_accounts[\"set.card_id\"]\n",
    "\n",
    "# combine only if there is a \"set\" column where it represents an update on the data with the same \"name\"\n",
    "# combining column \"set.address\" with \"data.address\" into a new column named \"address\"\n",
    "df_accounts[\"address\"] = df_accounts[\"set.address\"].combine_first(df_accounts[\"data.address\"])\n",
    "\n",
    "# combining column \"set.phone_number\" with \"data.phone_number\" into a new column named \"phone_number\"\n",
    "df_accounts[\"phone_number\"] = df_accounts[\"set.phone_number\"].combine_first(df_accounts[\"data.phone_number\"])\n",
    "\n",
    "# choosing the needed columns that's been cleaned\n",
    "cols = [\"id\",\"account_id\",\"name\",\"address\",\"phone_number\",\"email\",\"savings_account_id\",\"card_id\"]\n",
    "df_accounts = df_accounts[cols]\n",
    "\n",
    "# grouping all the datas by using \"id\" as reference and feeling the empty data with the the ones above it (updating from the previous data\n",
    "df_accounts = df_accounts.groupby(\"id\").ffill()\n",
    "\n",
    "print(\"\\nACCOUNTS:\")\n",
    "print(df_accounts.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1f3f1f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CARDS:\n",
      "  card_id card_number  credit_used  monthly_limit   status\n",
      "0      c1    11112222          0.0        30000.0  PENDING\n",
      "1      c1    11112222          0.0        30000.0   ACTIVE\n",
      "2      c1    11112222      12000.0        30000.0   ACTIVE\n",
      "3      c1    11112222      19000.0        30000.0   ACTIVE\n",
      "4      c1    11112222          0.0        30000.0   ACTIVE\n",
      "5      c1    11112222          0.0        30000.0   CLOSED\n",
      "6      c2    12123434          0.0        70000.0  PENDING\n",
      "7      c2    12123434          0.0        70000.0   ACTIVE\n",
      "8      c2    12123434      37000.0        70000.0   ACTIVE\n"
     ]
    }
   ],
   "source": [
    "# Feeling dataframe \"df_accounts\" with all the JSON data files located in \"./data/cards\" using load_and_normalize function\n",
    "df_cards = load_and_normalize(\"./data/cards\")\n",
    "\n",
    "# renaming and combining the features/columns\n",
    "df_cards[\"card_id\"] = df_cards[\"data.card_id\"]\n",
    "df_cards[\"card_number\"] = df_cards[\"data.card_number\"]\n",
    "df_cards[\"monthly_limit\"] = df_cards[\"data.monthly_limit\"]\n",
    "\n",
    "# combine only if there is a \"set\" column where it represents an update on the data with the same \"name\"\n",
    "# combining column \"set.credit_used\" with \"data.credit_used\" into a new column named \"credit_used\"\n",
    "df_cards[\"credit_used\"] = df_cards[\"set.credit_used\"].combine_first(df_cards[\"data.credit_used\"])\n",
    "\n",
    "# combining column \"set.status\" with \"data.status\" into a new column named \"status\"\n",
    "df_cards[\"status\"] = df_cards[\"set.status\"].combine_first(df_cards[\"data.status\"])\n",
    "\n",
    "# choosing the needed columns that's been cleaned\n",
    "cols = [\"id\",\"card_id\",\"card_number\",\"credit_used\",\"monthly_limit\",\"status\"]\n",
    "df_cards = df_cards[cols]\n",
    "\n",
    "# grouping all the datas by using \"id\" as reference and feeling the empty data with the the ones above it (updating from the previous data\n",
    "df_cards = df_cards.groupby(\"id\").ffill()\n",
    "\n",
    "print(\"\\nCARDS:\")\n",
    "print(df_cards.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a46ff369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAVING ACCOUNTS:\n",
      "  savings_account_id  balance  interest_rate_percent  status\n",
      "0                sa1      0.0                    1.5  ACTIVE\n",
      "1                sa1  15000.0                    1.5  ACTIVE\n",
      "2                sa1  15000.0                    3.0  ACTIVE\n",
      "3                sa1  40000.0                    3.0  ACTIVE\n",
      "4                sa1  21000.0                    3.0  ACTIVE\n",
      "5                sa1  21000.0                    1.5  ACTIVE\n",
      "6                sa1  21000.0                    4.0  ACTIVE\n",
      "7                sa1  33000.0                    4.0  ACTIVE\n"
     ]
    }
   ],
   "source": [
    "# Feeling dataframe \"df_accounts\" with all the JSON data files located in \"./data/cards\" using load_and_normalize function\n",
    "df_saving_accounts = load_and_normalize(\"./data/savings_accounts\")\n",
    "\n",
    "# renaming and combining the features/columns\n",
    "df_saving_accounts[\"savings_account_id\"] = df_saving_accounts[\"data.savings_account_id\"]\n",
    "df_saving_accounts[\"status\"] = df_saving_accounts[\"data.status\"]\n",
    "\n",
    "# combine only if there is a \"set\" column where it represents an update on the data with the same \"name\"\n",
    "# combining column \"set.balance\" with \"data.balance\" into a new column named \"balance\"\n",
    "df_saving_accounts[\"balance\"] = df_saving_accounts[\"set.balance\"].combine_first(df_saving_accounts[\"data.balance\"])\n",
    "\n",
    "# combining column \"set.interest_rate_percent\" with \"data.interest_rate_percent\" into a new column named \"interest_rate_percent\"\n",
    "df_saving_accounts[\"interest_rate_percent\"] = df_saving_accounts[\"set.interest_rate_percent\"].combine_first(df_saving_accounts[\"data.interest_rate_percent\"])\n",
    "\n",
    "# choosing the needed columns that's been cleaned\n",
    "cols = [\"id\",\"savings_account_id\",\"balance\",\"interest_rate_percent\",\"status\"]\n",
    "df_saving_accounts = df_saving_accounts[cols]\n",
    "\n",
    "# grouping all the datas by using \"id\" as reference and feeling the empty data with the the ones above it (updating from the previous data)\n",
    "df_saving_accounts = df_saving_accounts.groupby(\"id\").ffill()\n",
    "\n",
    "print(\"\\nSAVING ACCOUNTS:\")\n",
    "print(df_saving_accounts.to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
